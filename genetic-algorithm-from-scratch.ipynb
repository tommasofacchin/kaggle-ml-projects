{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54352381",
   "metadata": {
    "papermill": {
     "duration": 0.004386,
     "end_time": "2026-01-28T17:50:17.773809",
     "exception": false,
     "start_time": "2026-01-28T17:50:17.769423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Genetic Algorithms\n",
    "A genetic algorithm (GA) is a population‑based search method inspired by evolution and natural selection. It keeps a set of candidate solutions and iteratively updates them using selection, crossover, and mutation, all guided by a fitness function that encodes how good each solution is.\n",
    "\n",
    "Each candidate solution is encoded as a chromosome, usually a fixed‑length vector (for example a bitstring or a vector of real‑valued parameters). A population is just a collection of such chromosomes, and its size controls both how much of the search space you can explore and how expensive each generation is to evaluate.\n",
    "\n",
    "Genetic algorithms show up in many application domains, including engineering design and scheduling, automatic program synthesis, machine learning model and hyperparameter optimization, and the calibration of scientific models in areas like economics and biology.\n",
    "\n",
    "---\n",
    "\n",
    "## Algorithm Outline\n",
    "\n",
    "1. **Initialize a population of \\(N\\) random individuals**  \n",
    "   The algorithm starts with no prior knowledge, so it samples \\(N\\) chromosomes at random from the search space.  \n",
    "   Each chromosome is a candidate solution; the initial population is usually diverse and mostly low‑quality, but it covers different regions of the space.\n",
    "\n",
    "2. **Evaluate the fitness of all \\(N\\) individuals**  \n",
    "   For each chromosome, the fitness function computes a scalar score that measures how good that candidate solution is for the specific problem.  \n",
    "   Genetic algorithms are typically used as maximizers: higher fitness means a better solution.\n",
    "\n",
    "3. **Select pairs of individuals biased by fitness (survival of the fittest)**  \n",
    "   The next generation is produced by letting fitter individuals reproduce more often.  \n",
    "   A selection mechanism (e.g., tournament or roulette‑wheel) repeatedly chooses parents, so that individuals with higher fitness have a higher probability of being selected, while still allowing some randomness.\n",
    "\n",
    "4. **Apply crossover to selected parent pairs to generate offspring**  \n",
    "   Once parents are selected, crossover recombines their chromosomes. In one‑point crossover, for example, a random cut point is drawn and the parents exchange their tails, producing two children.  \n",
    "   This operation mixes genetic material from different individuals and can combine useful building blocks (good partial solutions).\n",
    "\n",
    "5. **Apply mutation to the offspring by randomly changing some genes**  \n",
    "   After crossover, each offspring undergoes mutation, which introduces small random perturbations.  \n",
    "   For bitstrings, this is often realized as bit‑flip mutation, where each gene is flipped with a small probability. Mutation helps maintain diversity and can enable the algorithm to escape local optima.\n",
    "\n",
    "6. **Form the new population (with optional elitism)**  \n",
    "   Offspring are generated until \\(N\\) new individuals have been created, forming the next generation.  \n",
    "   Many GA variants use elitism, i.e., they copy one or more of the best individuals from the previous generation into the new population to ensure that the best solutions found so far are not lost.\n",
    "\n",
    "7. **Check the termination criterion and repeat if needed**  \n",
    "   After building the new population, the algorithm evaluates the fitness of all individuals again.  \n",
    "   If the termination criterion is satisfied (e.g., a maximum number of generations, or a satisfactory fitness value), the algorithm returns the best individual found as the final solution; otherwise, it goes back to step 2 and starts a new generation.\n",
    "\n",
    "---\n",
    "\n",
    "## Limitations\n",
    "Genetic algorithms are heuristic search methods, so they generally do not guarantee convergence to a global optimum. In practice, the search moves locally in the space of populations and is guided by fitness values, which means a GA can get stuck in local optima or flat regions, especially when diversity is low or the fitness landscape is highly multimodal. For most realistic problems, the aim is therefore not to prove global optimality, but to find a reasonably good solution within a limited computational budget.\n",
    "\n",
    "Two common issues in genetic algorithms are premature convergence and loss of diversity.\n",
    "\n",
    "- **Premature convergence**: the population settles too quickly around a suboptimal solution, and the best or average fitness stops improving over generations. A flat fitness curve on its own is not a good stopping rule, because it might just mean the GA is stuck in a bad local optimum rather than having really “finished” the search.\n",
    "\n",
    "- **Loss of diversity**: individuals become very similar to each other, so crossover keeps generating almost identical offspring and the algorithm stops exploring new areas of the search space. You can often spot this when most chromosomes look alike or children barely differ from their parents.\n",
    "\n",
    "## Hyperparameters \n",
    "The behavior of a GA is mostly driven by its hyperparameters: population size, how selection is done, crossover and mutation rates, and how you encode candidate solutions. Population size and selection pressure decide how much you explore versus exploit, crossover and mutation decide how aggressively you search new regions, and the encoding (binary, integer, real‑valued, etc.) plus the chosen operators should fit the structure of the problem you are trying to solve.\n",
    "\n",
    "Since performance depends so much on these choices, a practical way to compare two GA setups is to run both several times on the same problem, plot the average best fitness over generations, and, if needed, look at the distribution of the final best fitness values (for example with boxplots) to see which setup tends to produce better solutions more reliably.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597327fb",
   "metadata": {
    "papermill": {
     "duration": 0.002784,
     "end_time": "2026-01-28T17:50:17.779501",
     "exception": false,
     "start_time": "2026-01-28T17:50:17.776717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# My implementation\n",
    "\n",
    "In this notebook I’ll work with a single, flexible `GeneticAlgorithm` class written in Python. It follows the usual GA loop we’ve just seen, but keeps most of the details configurable so I can reuse it in different problems without rewriting the core logic.\n",
    "\n",
    "When I create a `GeneticAlgorithm` object, I mainly decide three things:\n",
    "\n",
    "- how long chromosomes are (`chromosome_length`)\n",
    "- how I measure the quality of a solution (`fitness_func`)\n",
    "- how I want the population to evolve (population size, selection, crossover/mutation, elitism, random seed, …)\n",
    "\n",
    "Once these are set, the class handles the whole evolution process and returns the best solution it finds, plus some basic stats over generations.\n",
    "\n",
    "---\n",
    "\n",
    "## Design\n",
    "Here, each chromosome is just a Python list of genes (`List[Any]`). By default genes are bits (0 or 1), but since everything is typed as `Any` I can switch to integers, floats, characters, etc., as long as the fitness function knows what to do with them.\n",
    "\n",
    "The main constructor arguments are:\n",
    "\n",
    "- `chromosome_length`: number of genes per individual.\n",
    "- `fitness_func: List[Any] -> float`: takes one individual and returns a fitness score (higher is better).\n",
    "- `population_size`: how many individuals I keep in each generation (default 100).\n",
    "- `crossover_prob`, `mutation_prob`: how often I apply crossover and how likely each gene is to mutate.\n",
    "- `selection_strategy`: `\"tournament\"` (default) or `\"roulette\"`.\n",
    "- `tournament_size`: group size for tournament selection.\n",
    "- `crossover_operator`, `mutation_operator`: optional custom operators if I don’t want the defaults.\n",
    "- `gene_initializer`: function that samples a single gene (default: random bit 0/1).\n",
    "- `elitism`: whether I keep the best individual across generations.\n",
    "- `random_state`: optional seed to make runs reproducible.\n",
    "\n",
    "Internally, the class keeps:\n",
    "\n",
    "- `population`: the current list of individuals.\n",
    "- `fitness_values`: fitness scores for the current population.\n",
    "- `best_individual_`, `best_fitness_`: the best solution seen so far.\n",
    "- `history_`: a list of dictionaries with per‑generation stats (best and mean fitness).\n",
    "\n",
    "---\n",
    "\n",
    "## Population Initialization and Evaluation\n",
    "\n",
    "To start, `initialize_population` builds the first population by calling `gene_initializer` for each gene of each individual. Changing this initializer is enough to move from bitstrings to other encodings without touching the rest.\n",
    "\n",
    "Then `evaluate_population` runs `fitness_func` on every individual, stores the fitness values, and updates the current best solution. I call this once before the loop and then after each generation so I can track progress over time.\n",
    "\n",
    "---\n",
    "\n",
    "## Selection, Crossover, and Mutation\n",
    "\n",
    "For parent selection I support two strategies:\n",
    "\n",
    "- **Tournament selection** (`_select_parent_tournament`): I sample `tournament_size` random individuals and pick the one with the highest fitness.\n",
    "- **Roulette‑wheel selection** (`_select_parent_roulette`): I build probabilities proportional to fitness (after shifting if there are negative values) and sample according to those. If the total fitness is zero, I fall back to a uniform random choice.\n",
    "\n",
    "The method `select_parents` just wraps this and calls the right strategy based on `selection_strategy`.\n",
    "\n",
    "For variation I provide default operators but allow overrides:\n",
    "\n",
    "- **One‑point crossover** (`_one_point_crossover`): with probability `crossover_prob` I pick a cut point along the chromosome and swap the tails of the two parents to get two children; otherwise I simply copy the parents.\n",
    "- **Bit‑flip mutation** (`_bit_flip_mutation`): I go through each gene and flip it with probability `mutation_prob` (assuming binary genes). For other encodings I can pass a different `mutation_operator` when I build the GA.\n",
    "\n",
    "---\n",
    "\n",
    "## Generational Update and Elitism\n",
    "\n",
    "The method `step` builds the next generation from the current one:\n",
    "\n",
    "- If `elitism` is on, I first find the best individual in the current population and keep a copy as `elite`.\n",
    "- Then, until `new_population` reaches `population_size`:\n",
    "  - I select two parents with `select_parents`.\n",
    "  - I apply the crossover operator to get two children.\n",
    "  - I mutate both children.\n",
    "  - I add them to `new_population` (checking not to exceed the desired size).\n",
    "\n",
    "At the end, if elitism is enabled, I overwrite a random position in the new population with the `elite` individual. This guarantees that the best solution I’ve seen so far is never lost just because of unlucky crossover or mutation.\n",
    "\n",
    "Finally, I replace the old population with the new one.\n",
    "\n",
    "---\n",
    "\n",
    "## Running the Algorithm and Tracking History\n",
    "\n",
    "The main method I use is `run`:\n",
    "\n",
    "- It initializes the population and evaluates it once.\n",
    "- For `n_generations` steps it:\n",
    "  - computes best and mean fitness and appends them to `history_`,\n",
    "  - prints a short log line if `verbose=True`,\n",
    "  - calls an optional `callback(gen, population, fitness_values)` if I pass one,\n",
    "  - calls `step()` to produce the next generation,\n",
    "  - re‑evaluates the population.\n",
    "\n",
    "At the very end it stores one last snapshot in `history_` and returns:\n",
    "\n",
    "```python\n",
    "best_individual_, best_fitness_, history_\n",
    "```\n",
    "\n",
    "This makes it easy both to retrieve the final solution and to plot how the GA behaved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "122ae6d4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-28T17:50:17.789050Z",
     "iopub.status.busy": "2026-01-28T17:50:17.788592Z",
     "iopub.status.idle": "2026-01-28T17:50:17.829396Z",
     "shell.execute_reply": "2026-01-28T17:50:17.828505Z"
    },
    "papermill": {
     "duration": 0.048711,
     "end_time": "2026-01-28T17:50:17.831460",
     "exception": false,
     "start_time": "2026-01-28T17:50:17.782749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from typing import Callable, List, Tuple, Optional, Any, Dict\n",
    "\n",
    "class GeneticAlgorithm:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        chromosome_length: int,\n",
    "        fitness_func: Callable[[List[Any]], float],\n",
    "        population_size: int = 100,\n",
    "        crossover_prob: float = 0.8,\n",
    "        mutation_prob: float = 0.01,\n",
    "        selection_strategy: str = \"tournament\",\n",
    "        tournament_size: int = 3,\n",
    "        crossover_operator: Optional[Callable[[List[Any], List[Any]], Tuple[List[Any], List[Any]]]] = None,\n",
    "        mutation_operator: Optional[Callable[[List[Any], float], List[Any]]] = None,\n",
    "        gene_initializer: Optional[Callable[[], Any]] = None,\n",
    "        elitism: bool = True,\n",
    "        random_state: Optional[int] = None,\n",
    "    ):\n",
    "        self.chromosome_length = chromosome_length\n",
    "        self.fitness_func = fitness_func\n",
    "        self.population_size = population_size\n",
    "        self.crossover_prob = crossover_prob\n",
    "        self.mutation_prob = mutation_prob\n",
    "        self.selection_strategy = selection_strategy\n",
    "        self.tournament_size = tournament_size\n",
    "        self.crossover_operator = crossover_operator\n",
    "        self.mutation_operator = mutation_operator\n",
    "        self.gene_initializer = gene_initializer\n",
    "        self.elitism = elitism\n",
    "\n",
    "        self.random_state = random_state\n",
    "        if random_state is not None:\n",
    "            random.seed(random_state)\n",
    "            np.random.seed(random_state)\n",
    "\n",
    "        \n",
    "        self.population: List[List[Any]] = []\n",
    "        self.fitness_values: List[float] = []\n",
    "        self.best_individual_: Optional[List[Any]] = None\n",
    "        self.best_fitness_: Optional[float] = None\n",
    "        self.history_: List[Dict[str, float]] = []\n",
    "\n",
    "        # Default\n",
    "        if self.gene_initializer is None:\n",
    "            # default: bitstring 0/1\n",
    "            self.gene_initializer = lambda: random.randint(0, 1)\n",
    "\n",
    "        if self.crossover_operator is None:\n",
    "            self.crossover_operator = self._one_point_crossover\n",
    "\n",
    "        if self.mutation_operator is None:\n",
    "            self.mutation_operator = self._bit_flip_mutation\n",
    "\n",
    "\n",
    "    # Init\n",
    "    def initialize_population(self):\n",
    "        self.population = [\n",
    "            [self.gene_initializer() for _ in range(self.chromosome_length)]\n",
    "            for _ in range(self.population_size)\n",
    "        ]\n",
    "\n",
    "    def evaluate_population(self):\n",
    "        self.fitness_values = [self.fitness_func(ind) for ind in self.population]\n",
    "\n",
    "        gen_best_idx = int(np.argmax(self.fitness_values))\n",
    "        gen_best_fit = self.fitness_values[gen_best_idx]\n",
    "        gen_best_ind = self.population[gen_best_idx]\n",
    "\n",
    "        if (self.best_fitness_ is None) or (gen_best_fit > self.best_fitness_):\n",
    "            self.best_fitness_ = gen_best_fit\n",
    "            self.best_individual_ = gen_best_ind.copy()\n",
    "\n",
    "    # Selection\n",
    "    def _select_parent_tournament(self) -> List[Any]:\n",
    "        indices = np.random.choice(\n",
    "            len(self.population), size=self.tournament_size, replace=False\n",
    "        )\n",
    "        best_idx = indices[0]\n",
    "        best_fit = self.fitness_values[best_idx]\n",
    "        for idx in indices[1:]:\n",
    "            if self.fitness_values[idx] > best_fit:\n",
    "                best_fit = self.fitness_values[idx]\n",
    "                best_idx = idx\n",
    "        return self.population[best_idx]\n",
    "\n",
    "    def _select_parent_roulette(self) -> List[Any]:\n",
    "        fitness_array = np.array(self.fitness_values, dtype=float)\n",
    "        min_fit = fitness_array.min()\n",
    "        if min_fit < 0:\n",
    "            fitness_array -= min_fit \n",
    "        total_fit = fitness_array.sum()\n",
    "        if total_fit == 0:\n",
    "            idx = np.random.randint(len(self.population))\n",
    "            return self.population[idx]\n",
    "\n",
    "        probs = fitness_array / total_fit\n",
    "        idx = np.random.choice(len(self.population), p=probs)\n",
    "        return self.population[idx]\n",
    "\n",
    "    def select_parents(self) -> Tuple[List[Any], List[Any]]:\n",
    "        if self.selection_strategy == \"roulette\":\n",
    "            p1 = self._select_parent_roulette()\n",
    "            p2 = self._select_parent_roulette()\n",
    "        else:\n",
    "            # default: tournament\n",
    "            p1 = self._select_parent_tournament()\n",
    "            p2 = self._select_parent_tournament()\n",
    "        return p1, p2\n",
    "\n",
    "    # Crossover and mutation\n",
    "    def _one_point_crossover(\n",
    "        self,\n",
    "        parent1: List[Any],\n",
    "        parent2: List[Any],\n",
    "    ) -> Tuple[List[Any], List[Any]]:\n",
    "        if len(parent1) != len(parent2):\n",
    "            raise ValueError(\"Chromosomes must have the same length for the crossover.\")\n",
    "\n",
    "        if random.random() > self.crossover_prob:\n",
    "            return parent1.copy(), parent2.copy()\n",
    "\n",
    "        point = random.randint(1, len(parent1) - 1) \n",
    "        child1 = parent1[:point] + parent2[point:]\n",
    "        child2 = parent2[:point] + parent1[point:]\n",
    "        return child1, child2\n",
    "\n",
    "    def _bit_flip_mutation(\n",
    "        self,\n",
    "        individual: List[Any],\n",
    "        mutation_prob: float,\n",
    "    ) -> List[Any]:\n",
    "        mutated = []\n",
    "        for gene in individual:\n",
    "            if random.random() < mutation_prob:\n",
    "                mutated.append(1 - gene)  \n",
    "            else:\n",
    "                mutated.append(gene)\n",
    "        return mutated\n",
    "\n",
    "    # Generation\n",
    "    def step(self):\n",
    "        new_population: List[List[Any]] = []\n",
    "\n",
    "        # Elitism\n",
    "        elite = None\n",
    "        if self.elitism:\n",
    "            best_idx = int(np.argmax(self.fitness_values))\n",
    "            elite = self.population[best_idx].copy()\n",
    "\n",
    "        # Generate new population\n",
    "        while len(new_population) < self.population_size:\n",
    "            parent1, parent2 = self.select_parents()\n",
    "            child1, child2 = self.crossover_operator(parent1, parent2)\n",
    "\n",
    "            child1 = self.mutation_operator(child1, self.mutation_prob)\n",
    "            child2 = self.mutation_operator(child2, self.mutation_prob)\n",
    "\n",
    "            new_population.append(child1)\n",
    "            if len(new_population) < self.population_size:\n",
    "                new_population.append(child2)\n",
    "\n",
    "        if self.elitism and elite is not None:\n",
    "            replace_idx = random.randint(0, self.population_size - 1)\n",
    "            new_population[replace_idx] = elite\n",
    "\n",
    "        self.population = new_population\n",
    "\n",
    "    # Run\n",
    "    def run(\n",
    "        self,\n",
    "        n_generations: int = 100,\n",
    "        callback: Optional[Callable[[int, List[List[Any]], List[float]], None]] = None,\n",
    "        verbose: bool = False,\n",
    "    ) -> Tuple[List[Any], float, List[Dict[str, float]]]:\n",
    "        \"\"\"\n",
    "        Run the algo for n_generations.\n",
    "        Return:\n",
    "            best_individual, best_fitness, history\n",
    "        \"\"\"\n",
    "        self.initialize_population()\n",
    "        self.evaluate_population()\n",
    "\n",
    "        self.history_ = []\n",
    "        for gen in range(n_generations):\n",
    "            best_fit = float(np.max(self.fitness_values))\n",
    "            mean_fit = float(np.mean(self.fitness_values))\n",
    "\n",
    "            self.history_.append(\n",
    "                {\n",
    "                    \"generation\": gen,\n",
    "                    \"best_fitness\": best_fit,\n",
    "                    \"mean_fitness\": mean_fit,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"Gen {gen:4d} | \"\n",
    "                    f\"best: {best_fit:.4f} | mean: {mean_fit:.4f}\"\n",
    "                )\n",
    "\n",
    "            if callback is not None:\n",
    "                callback(gen, self.population, self.fitness_values)\n",
    "\n",
    "            self.step()\n",
    "            self.evaluate_population()\n",
    "\n",
    "        best_fit = float(np.max(self.fitness_values))\n",
    "        mean_fit = float(np.mean(self.fitness_values))\n",
    "\n",
    "        self.history_.append(\n",
    "            {\n",
    "                \"generation\": n_generations,\n",
    "                \"best_fitness\": best_fit,\n",
    "                \"mean_fitness\": mean_fit,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Gen {n_generations:4d} | \"\n",
    "                f\"best: {best_fit:.4f} | mean: {mean_fit:.4f}\"\n",
    "            )\n",
    "\n",
    "        return self.best_individual_, self.best_fitness_, self.history_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905e01b7",
   "metadata": {
    "papermill": {
     "duration": 0.002704,
     "end_time": "2026-01-28T17:50:17.837116",
     "exception": false,
     "start_time": "2026-01-28T17:50:17.834412",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Example 1 – Bitstring optimization (OneMax)\n",
    "\n",
    "As a first example I will apply the `GeneticAlgorithm` class to a very simple binary optimization problem. The goal is to evolve a bitstring of fixed length so that it contains as many ones as possible. This problem is often called *OneMax*: given a chromosome $\\mathbf{x} = (x_1, \\dots, x_L)$ with $x_i \\in \\{0, 1\\}$, the fitness is just the sum of its bits\n",
    "$$\n",
    "\\text{fitness}(\\mathbf{x}) = \\sum_{i=1}^L x_i.\n",
    "$$\n",
    "\n",
    "In this setting:\n",
    "\n",
    "- the chromosome is a binary vector of length \\(L\\);\n",
    "- the default gene initializer (random 0/1) is exactly what we need;\n",
    "- the fitness function simply counts the number of ones in the chromosome.\n",
    "\n",
    "The global optimum is the all‑ones string, so it is easy to check whether the GA is behaving as expected and to visualize how quickly it converges to the optimum.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6e122d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T17:50:17.846221Z",
     "iopub.status.busy": "2026-01-28T17:50:17.845408Z",
     "iopub.status.idle": "2026-01-28T17:50:17.979839Z",
     "shell.execute_reply": "2026-01-28T17:50:17.978822Z"
    },
    "papermill": {
     "duration": 0.140586,
     "end_time": "2026-01-28T17:50:17.981799",
     "exception": false,
     "start_time": "2026-01-28T17:50:17.841213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen   0 | best fitness: 27 | best: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0]\n",
      "Gen   1 | best fitness: 28 | best: [1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "Gen   2 | best fitness: 31 | best: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0]\n",
      "Gen   3 | best fitness: 33 | best: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0]\n",
      "Gen   4 | best fitness: 33 | best: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1]\n",
      "Gen   5 | best fitness: 35 | best: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "Gen   6 | best fitness: 37 | best: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Gen   7 | best fitness: 38 | best: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Gen   8 | best fitness: 39 | best: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Gen   9 | best fitness: 39 | best: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Gen  10 | best fitness: 39 | best: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Gen  11 | best fitness: 39 | best: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Gen  12 | best fitness: 40 | best: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Gen  13 | best fitness: 40 | best: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Gen  14 | best fitness: 40 | best: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Gen  15 | best fitness: 40 | best: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Gen  16 | best fitness: 40 | best: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Gen  17 | best fitness: 40 | best: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Gen  18 | best fitness: 40 | best: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Gen  19 | best fitness: 40 | best: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "Best fitness: 40.0\n",
      "Best individual: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Fitness function: count the number of ones\n",
    "def onemax_fitness(individual: List[Any]) -> float:\n",
    "    # individual is a list of 0/1 values\n",
    "    return float(sum(individual))\n",
    "\n",
    "chromosome_length = 40\n",
    "population_size = 100\n",
    "n_generations = 20\n",
    "\n",
    "ga_onemax = GeneticAlgorithm(\n",
    "    chromosome_length=chromosome_length,\n",
    "    fitness_func=onemax_fitness,\n",
    "    population_size=population_size,\n",
    "    crossover_prob=0.8,\n",
    "    mutation_prob=0.01,\n",
    "    selection_strategy=\"tournament\",\n",
    "    tournament_size=3,\n",
    "    elitism=True,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "def onemax_callback(gen: int, population, fitness_values):\n",
    "    best_idx = int(np.argmax(fitness_values))\n",
    "    best = population[best_idx]\n",
    "    best_fit = fitness_values[best_idx]\n",
    "    print(f\"Gen {gen:3d} | best fitness: {best_fit:.0f} | best: {best}\")\n",
    "\n",
    "best_ind, best_fit, history = ga_onemax.run(\n",
    "    n_generations=n_generations,\n",
    "    verbose=False,              \n",
    "    callback=onemax_callback,  \n",
    ")\n",
    "\n",
    "print(\"\\nBest fitness:\", best_fit)\n",
    "print(\"Best individual:\", best_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0590bf",
   "metadata": {
    "papermill": {
     "duration": 0.002848,
     "end_time": "2026-01-28T17:50:17.987677",
     "exception": false,
     "start_time": "2026-01-28T17:50:17.984829",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Example 2 – Evolving a Text String\n",
    "\n",
    "In the second example I use the `GeneticAlgorithm` class to evolve a target sentence character by character. Each chromosome is a sequence of characters, and the GA tries to make this sequence match a fixed target string.\n",
    "\n",
    "Here:\n",
    "- The chromosome is a list of characters with the same length as the target sentence.\n",
    "- The gene initializer samples random characters from a fixed alphabet (letters, spaces, punctuation).\n",
    "- The fitness function compares the candidate string to the target and returns the fraction of characters that are correct in the correct position.\n",
    "- Mutation randomly replaces characters with new ones from the alphabet, while crossover works as before, recombining substrings from two parents.\n",
    "\n",
    "Because the fitness is normalized between 0 and 1, it is easy to monitor how close the current best individual is to the target sentence. By printing the best string every few generations, we can watch the GA gradually turn random noise into a readable sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d34ae4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T17:50:17.995109Z",
     "iopub.status.busy": "2026-01-28T17:50:17.994695Z",
     "iopub.status.idle": "2026-01-28T17:50:19.880072Z",
     "shell.execute_reply": "2026-01-28T17:50:19.878779Z"
    },
    "papermill": {
     "duration": 1.891422,
     "end_time": "2026-01-28T17:50:19.882060",
     "exception": false,
     "start_time": "2026-01-28T17:50:17.990638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0] 'xs,jB,VQ,KemWD,kb JjhjlYJ.JI,HadfpDEQ X,HGwlSA'Fgb.SMqnOyMOvVGKbIllmsYlFbz.iuNF'\n",
      "[ 10] 'xs,Fvyq.lnemAi,bb JdhjlnJ.JI,H FBaGCS'snYLO,eJaDZvdmWkasGca.ToCBk sttiXyUpkVEy.'\n",
      "[ 20] 'Hs, byqnPYemWO,Nb JjhBlYJ'JI,H FBaGCS'snYeO,eJaDZv.nWaasGca.ToCBkS'tkCWveTkVEy.'\n",
      "[ 30] 'Hs, xyqnPYeaiYTZK JjvBlaJ'JI,H FBaGRS'snNeO,eusjhbFnbkashNa.To'Bkr'tkCEveTkVEy.'\n",
      "[ 40] 'Hs, byqnPYeaiYTFo JjaqlaJ'JI,H FBacRS'saYeg,e stZdfnthaAhNa.ToCBkrktkCWverkVqy.'\n",
      "[ 50] 'Hs, MyqnaYeaiYTFo JjvBiaJ'JIVH FTayRz'sniegSe studAnbiashCa.ToCBkr'tkcWverkiJy.'\n",
      "[ 60] 'Hsf MyonaYeaisTFo JjaolanWJI'H aBayRzusnienSe sTudenbiashCa.ToXUkr'DkCWXersiGy.'\n",
      "[ 70] 'HR, MyonaYeaisTko Jjmolan JI'H atacRS'sbienSe studenbias Ca.ToCUkr'tkcWversiNy.'\n",
      "[ 80] 'Hu, MyonaYeaisTRo JjaolanaJI'H atacRS'sbienSe studenbvas CauFoC'Yr'tuciversiGy.'\n",
      "[ 90] 'Hl,AMyqnaAeAisJRo JYaolana I'H atacRS'sbienSe studentBas CauFoC'YrQtuniversiIy.'\n",
      "[100] 'HM, MyonaseAistRomJYaolana I'H attaRS'sbienSe studentBas CauFoCoYr'tuniversiIy.'\n",
      "[110] 'Hv, MyYnameAis.domJYToqana I'H axtaRS'sbience studentvas CauFoC'ar'tuniversiIy.'\n",
      "[120] 'HM, Myoname is.SomJYTolanB I'H axtawS'sbience studentBas CauFoX'ar'wuniversiLy.'\n",
      "[130] 'Hi, Myoname is.comJaTolanA I'H axvaw'csbience studentBas CaqFoC'ar'wuniversiLy.'\n",
      "[140] 'Hi, Myoname qs.comPaTo anJ I'H axtaPJcscience student as CauFoC'ar'tuniversiYy.'\n",
      "[150] 'Hi, Myoname is.comPaTo anJ I'H aZtawJcscience student as CaQFoCWar'kuniversiIy.'\n",
      "[160] 'Hi, Myoname isccomSaTo anJ I'H aZtawJcscience student at CaUFoCLar'Juniversiyy.'\n",
      "[170] 'Hi, Fyoname is.comKaTo anJ I't anfaCJ science student at CauFoCLar'JuniversiTy.'\n",
      "[180] 'Hi, cyYname is.comSaTo anJ I't anfaCJ science student at CaIFoCLar'JuniversiTy.'\n",
      "[190] 'Hi, cyYname is.comSaTo anJ I'm anfahJ science student at CauFoCwar'ouniversiTy.'\n",
      "[200] 'Hi, cyYname is.comSaTo asJ I'm andahf science student at Ca'FoQBardVuniversiTy.'\n",
      "[210] 'Hi, cy name is.comSaTo asJ I'm anda,f science student at Ca'FoCBardouniversiyy.'\n",
      "[220] 'Hi, cy name is.comMaTo anJ I'm a daPJ science student at Ca'FoCvardVuniversiTy.'\n",
      "[230] 'Hi, cy name is.comMaTo anJ I'm a daPa science student at Ca'FoCvardnuniversixy.'\n",
      "[240] 'Hi, ,y name is.lomMaTo anJ I'm a daPa science student at Ca'FoCvardFuniversiTy.'\n",
      "[250] 'Hi, ,y name is.lomMaTo anJ I'm a daPa science student at Ca'FosvardFuniversiTy.'\n",
      "[260] 'Hi, my name is.comMaTo anJ I'm a da a science student at Ca'FosvardFuniversiTy.'\n",
      "[270] 'Hi, my name is.comMaTo and I'm a dasa rcience student at Ca'FosvarinuniversiTy.'\n",
      "[280] 'Hi, my name is.commaTo and I'msa da a science student at Ca'FosvarinuniversiTy.'\n",
      "[290] 'Hi, my name is commaTo and I'msa da a science student at Ca'FosvarinuniversiTy.'\n",
      "[300] 'Hi, my name is commaTo and I'mVa da a science student at Ca'FosvariUuniversiTy.'\n",
      "[310] 'Hi, my name is commaTo and I'mVa da a science student at Ca'FosvariUuniversiTy.'\n",
      "[320] 'Hi, my name is commaTo and I'mVa da a science student at Ca'FosvariUuniversiTy.'\n",
      "[330] 'Hi, my name is commaTo and I'mVa da a science student at Ca'FosvariUuniversiTy.'\n",
      "[340] 'Hi, my name is commajo and I'mVa da a science student at Ca'Fos,ari'universiTy.'\n",
      "[350] 'Hi, my name is Tommajo and I'mVa da a science student at Ca'FosqariLuniversiTy.'\n",
      "[360] 'Hi, my name is Tommajo and I'mVa da a science student at Ca'FosqariLuniversiTy.'\n",
      "[370] 'Hi, my name is TommaNo and I'mVa data science student at Ca'FosQariLuniversiTy.'\n",
      "[380] 'Hi, my name is TommaNo and I'mVa data science student at Ca'FosQariLuniversiLy.'\n",
      "[390] 'Hi, my name is TommaNo and I'mVa data science student at Ca'FosQariiuniversiLy.'\n",
      "[400] 'Hi, my name is TommaNo and I'mVa data science student at Ca'Foswari universiHy.'\n",
      "[410] 'Hi, my name is Tommayo and I'mVa data science student at Ca'Foswari universiwy.'\n",
      "[420] 'Hi, my name is Tommayo and I'mVa data science student at Ca'FosTari universivy.'\n",
      "[430] 'Hi, my name is Tommayo and I'mVa data science student at Ca'Foscari universivy.'\n",
      "[440] 'Hi, my name is Tommayo and I'mVa data science student at Ca'Foscari universivy.'\n",
      "[450] 'Hi, my name is Tommayo and I'mVa data science student at Ca'Foscari universivy.'\n",
      "[460] 'Hi, my name is Tommayo and I'mqa data science student at Ca'Foscari universivy.'\n",
      "[470] 'Hi, my name is TommaMo and I'mQa data science student at Ca'Foscari university.'\n",
      "[480] 'Hi, my name is TommaMo and I'mQa data science student at Ca'Foscari university.'\n",
      "[490] 'Hi, my name is TommaMo and I'mpa data science student at Ca'Foscari university.'\n",
      "\n",
      "=== Results ===\n",
      "Target: Hi, my name is Tommaso and I'm a data science student at Ca'Foscari university.\n",
      "Best  : Hi, my name is TommaMo and I'mQa data science student at Ca'Foscari university.\n",
      "Fitness: 0.9746835443037974\n"
     ]
    }
   ],
   "source": [
    "target = \"Hi, my name is Tommaso and I'm a data science student at Ca'Foscari university.\"\n",
    "alphabet = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ ,.'\"\n",
    "\n",
    "def fitness_string(individual: List[Any]) -> float:\n",
    "    s = \"\".join(individual)\n",
    "    correct = sum(c1 == c2 for c1, c2 in zip(s, target))\n",
    "    return correct / len(target)\n",
    "\n",
    "def init_gene_char() -> str:\n",
    "    return random.choice(alphabet)\n",
    "\n",
    "def char_mutation(individual: List[Any], mutation_prob: float) -> List[Any]:\n",
    "    mutated = []\n",
    "    for gene in individual:\n",
    "        if random.random() < mutation_prob:\n",
    "            mutated.append(random.choice(alphabet))\n",
    "        else:\n",
    "            mutated.append(gene)\n",
    "    return mutated\n",
    "\n",
    "ga_str = GeneticAlgorithm(\n",
    "    chromosome_length=len(target),\n",
    "    fitness_func=fitness_string,\n",
    "    population_size=80,\n",
    "    crossover_prob=0.8,\n",
    "    mutation_prob=0.02,\n",
    "    selection_strategy=\"tournament\",\n",
    "    elitism=True,\n",
    "    gene_initializer=init_gene_char,\n",
    "    mutation_operator=char_mutation,\n",
    "    random_state=123,\n",
    ")\n",
    "\n",
    "def print_best_string(gen: int, population, fitness_values):\n",
    "    if gen % 10 == 0:\n",
    "        best_idx = int(np.argmax(fitness_values))\n",
    "        best = population[best_idx]\n",
    "        best_str = \"\".join(best)\n",
    "        best_fit = fitness_values[best_idx]\n",
    "        print(f\"[{gen:3d}] '{best_str}'\")\n",
    "\n",
    "best_individual_str, best_fitness_str, history_str = ga_str.run(\n",
    "    n_generations=500,\n",
    "    callback=print_best_string,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "print(\"\\n=== Results ===\")\n",
    "print(\"Target:\", target)\n",
    "print(\"Best  :\", \"\".join(best_individual_str))\n",
    "print(\"Fitness:\", best_fitness_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bcac0f",
   "metadata": {
    "papermill": {
     "duration": 0.003309,
     "end_time": "2026-01-28T17:50:19.889166",
     "exception": false,
     "start_time": "2026-01-28T17:50:19.885857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Example 3 – Feature selection on the Wine dataset\n",
    "\n",
    "In the last example I use the `GeneticAlgorithm` class for a small but realistic feature selection task. The dataset is the classic Wine dataset from scikit‑learn: each sample is a wine characterized by 13 chemical analysis features and a class label indicating its cultivar.\n",
    "\n",
    "Here, each chromosome is a binary mask over the 13 input features. A gene equal to 1 means that the corresponding feature is used, while 0 means that the feature is dropped. The fitness of an individual is defined as the cross‑validated classification accuracy of a Logistic Regression model trained only on the selected features, minus a small penalty proportional to the fraction of features used. This encourages the GA to find compact subsets of features that still give good predictive performance.\n",
    "\n",
    "This example shows how to plug a real scikit‑learn model into the fitness function and use the same GA infrastructure to search over combinatorial subsets of features instead of simple bitstrings or characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6d15cae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T17:50:19.897509Z",
     "iopub.status.busy": "2026-01-28T17:50:19.897170Z",
     "iopub.status.idle": "2026-01-28T17:50:23.183934Z",
     "shell.execute_reply": "2026-01-28T17:50:23.182806Z"
    },
    "papermill": {
     "duration": 3.293421,
     "end_time": "2026-01-28T17:50:23.185945",
     "exception": false,
     "start_time": "2026-01-28T17:50:19.892524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (178, 13)\n",
      "y shape: (178,)\n",
      "Feature names: ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "Target classes: ['class_0' 'class_1' 'class_2']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  target  \n",
       "0                          3.92   1065.0       0  \n",
       "1                          3.40   1050.0       0  \n",
       "2                          3.17   1185.0       0  \n",
       "3                          3.45   1480.0       0  \n",
       "4                          2.93    735.0       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "data = load_wine()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Feature names:\", data.feature_names)\n",
    "print(\"Target classes:\", data.target_names)\n",
    "\n",
    "df = pd.DataFrame(X, columns=data.feature_names)\n",
    "df[\"target\"] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb21d81a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-28T17:50:23.196186Z",
     "iopub.status.busy": "2026-01-28T17:50:23.195431Z",
     "iopub.status.idle": "2026-01-28T17:50:53.630346Z",
     "shell.execute_reply": "2026-01-28T17:50:53.629420Z"
    },
    "papermill": {
     "duration": 30.446039,
     "end_time": "2026-01-28T17:50:53.636080",
     "exception": false,
     "start_time": "2026-01-28T17:50:23.190041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0] fit=0.943 | sel=9/13 | features=alcohol, ash, alcalinity_of_ash, magnesium, flavanoids, nonflavanoid_phenols, color_intensity, od280/od315_of_diluted_wines, proline\n",
      "\n",
      "[  1] fit=0.962 | sel=7/13 | features=alcohol, ash, alcalinity_of_ash, nonflavanoid_phenols, hue, od280/od315_of_diluted_wines, proline\n",
      "\n",
      "[  2] fit=0.962 | sel=7/13 | features=alcohol, ash, alcalinity_of_ash, nonflavanoid_phenols, hue, od280/od315_of_diluted_wines, proline\n",
      "\n",
      "[  3] fit=0.966 | sel=6/13 | features=alcohol, ash, alcalinity_of_ash, hue, od280/od315_of_diluted_wines, proline\n",
      "\n",
      "[  4] fit=0.966 | sel=6/13 | features=alcohol, ash, alcalinity_of_ash, hue, od280/od315_of_diluted_wines, proline\n",
      "\n",
      "[  5] fit=0.966 | sel=6/13 | features=alcohol, ash, alcalinity_of_ash, hue, od280/od315_of_diluted_wines, proline\n",
      "\n",
      "[  6] fit=0.966 | sel=6/13 | features=alcohol, ash, alcalinity_of_ash, hue, od280/od315_of_diluted_wines, proline\n",
      "\n",
      "[  7] fit=0.968 | sel=7/13 | features=alcohol, ash, alcalinity_of_ash, flavanoids, hue, od280/od315_of_diluted_wines, proline\n",
      "\n",
      "[  8] fit=0.968 | sel=7/13 | features=alcohol, ash, alcalinity_of_ash, flavanoids, hue, od280/od315_of_diluted_wines, proline\n",
      "\n",
      "[  9] fit=0.968 | sel=7/13 | features=alcohol, ash, alcalinity_of_ash, flavanoids, hue, od280/od315_of_diluted_wines, proline\n",
      "\n",
      "\n",
      "=== Wine feature selection results ===\n",
      "Best fitness: 0.9675213675213675\n",
      "Selected features: 7 / 13 ( alcohol, ash, alcalinity_of_ash, flavanoids, hue, od280/od315_of_diluted_wines, proline )\n",
      "\n",
      "Accuracy with all features: 0.972\n",
      "Accuracy with GA-selected features: 0.994\n"
     ]
    }
   ],
   "source": [
    "n_features = X.shape[1]\n",
    "\n",
    "# Build a simple pipeline: scaling + logistic regression\n",
    "base_model = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"logreg\", LogisticRegression(max_iter=1000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fitness function: CV accuracy - penalty for using many features\n",
    "def wine_feature_fitness(individual: List[Any]) -> float:\n",
    "    mask = np.array(individual, dtype=bool)\n",
    "\n",
    "    # Avoid empty or degenerate masks\n",
    "    if mask.sum() == 0:\n",
    "        return 0.0\n",
    "\n",
    "    X_sel = X[:, mask]\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        base_model,\n",
    "        X_sel,\n",
    "        y,\n",
    "        cv=3,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    mean_score = float(scores.mean())\n",
    "\n",
    "    # Penalty term: fraction of selected features\n",
    "    feature_fraction = mask.sum() / n_features\n",
    "    penalty = 0.05 * feature_fraction \n",
    "\n",
    "    return mean_score - penalty\n",
    "\n",
    "# GA setup\n",
    "chromosome_length = n_features\n",
    "population_size = 100\n",
    "n_generations = 10\n",
    "\n",
    "ga_wine = GeneticAlgorithm(\n",
    "    chromosome_length=chromosome_length,\n",
    "    fitness_func=wine_feature_fitness,\n",
    "    population_size=population_size,\n",
    "    crossover_prob=0.8,\n",
    "    mutation_prob=0.05,\n",
    "    selection_strategy=\"tournament\",\n",
    "    tournament_size=3,\n",
    "    elitism=True,\n",
    "    random_state=123,\n",
    ")\n",
    "\n",
    "from typing import List, Any\n",
    "import numpy as np\n",
    "\n",
    "def wine_callback(gen: int, population: List[List[Any]], fitness_values: List[float]):\n",
    "    best_idx = int(np.argmax(fitness_values))\n",
    "    best = population[best_idx]\n",
    "    best_fit = fitness_values[best_idx]\n",
    "    mask = np.array(best, dtype=bool)\n",
    "    n_sel = mask.sum()\n",
    "    selected_features = np.array(data.feature_names)[mask]\n",
    "    print(f\"[{gen:3d}] fit={best_fit:.3f} | sel={n_sel}/{n_features} | features={', '.join(selected_features)}\\n\")\n",
    "\n",
    "best_mask, best_fit, history_wine = ga_wine.run(\n",
    "    n_generations=n_generations,\n",
    "    callback=wine_callback,  \n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "best_mask = np.array(best_mask, dtype=bool)\n",
    "selected = np.array(data.feature_names)[best_mask]\n",
    "\n",
    "print(\"\\n=== Wine feature selection results ===\")\n",
    "print(\"Best fitness:\", best_fit)\n",
    "print(\"Selected features:\", best_mask.sum(), \"/\", n_features, \"(\", \", \".join(map(str, selected)), \")\")\n",
    "\n",
    "# Compare accuracy with all features vs selected subset\n",
    "scores_all = cross_val_score(base_model, X, y, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "scores_sel = cross_val_score(base_model, X[:, best_mask], y, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "\n",
    "print(f\"\\nAccuracy with all features: {scores_all.mean():.3f}\")\n",
    "print(f\"Accuracy with GA-selected features: {scores_sel.mean():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 41.788112,
   "end_time": "2026-01-28T17:50:56.260190",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-28T17:50:14.472078",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
